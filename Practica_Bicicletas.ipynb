{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kcvoUSXkccu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import numpy\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import tensorflow\n",
        "import keras\n",
        "import sklearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "Historia=1\n",
        "BATCHSIZE=1\n",
        "EPOCAS=1\n",
        "LSTM_DIM=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08B9RzzOkccx",
        "outputId": "eb682a08-e0e7-443b-b8c0-9ea31e10c7d1"
      },
      "outputs": [],
      "source": [
        "print (sys.version_info)\n",
        "print (\"NumPy: \", numpy.__version__)\n",
        "print (\"Pandas: \", pd.__version__)\n",
        "print (\"TensorFlow: \", tensorflow.__version__)\n",
        "print (\"Keras: \", keras.__version__)\n",
        "print (\"SciKitLearn: \", sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-bk9s-Lkccy"
      },
      "source": [
        "<h1>Carga del fichero</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "WeG7c2Jikccz",
        "outputId": "3765b437-1396-4621-c6bd-04d0adb1a936",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/day.csv'\n",
        "dfBikes=pd.read_csv (path)\n",
        "\n",
        "\n",
        "dfBikes.rename(columns = {'instant':'Id', 'dteday':'Fecha',\n",
        "                     \"season\":'Estacion', 'yr':'Anio', 'mnth':'Mes',\n",
        "                     'holiday':'Festivo','weekday':'DiaSemana','workingday':'DiaTrabajo','weathersit':'Tiempo','Temperatura':'temp','SensacionTemperatura':'atemp','Humedad':'hum','windspeed':'VelocidadViento','casual':'Casual','registered':'Registrado','cnt':'Cuenta'}, inplace=True)\n",
        "\n",
        "dfBikes.sort_values(['Id'], inplace=True)\n",
        "dfBikes.dropna(inplace=True)\n",
        "dfBikes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKJ-xQffkcc0"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54YHI5TCkcc0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Convertir los datos en un formato adecuado para entrenar modelos de series temporales, en este caso LSTM\n",
        "def CreaDatos(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return array(X), array(y)\n",
        "\n",
        "\n",
        "#funcion para visualizar en un grafico la prediccion y el valor real\n",
        "#aqui se desnormalizan los datos. Para ello, se despeja la formula de normalizacion\n",
        "def CalculoRMSE (titulo2):\n",
        "\n",
        "    testPredict = model.predict(testX, batch_size=BATCHSIZE)*(MaxRealY - MinRealY) + MinRealY\n",
        "    testReal=testY[:,13]*(MaxRealY - MinRealY) + MinRealY\n",
        "\n",
        "    testScore = math.sqrt(mean_squared_error(testReal, testPredict.reshape(-1,1)))\n",
        "\n",
        "    plt.plot (testPredict, label=\"Predic\")\n",
        "    plt.plot (testReal, label=\"Real\")\n",
        "    plt.legend ()\n",
        "    plt.title (\"Prediccion de bicicletas alquiladas en el dia.\\n\"+titulo2+\" Historia=\"+str (Historia)+\" Epocas=\"+str (EPOCAS)+ \" LSTM_dim=\"+str (LSTM_DIM))\n",
        "    plt.show()\n",
        "    return testScore\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_VovgMVkcc0"
      },
      "source": [
        "<h1>Procesamiento de los datos</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzIqnYKEkcc1",
        "outputId": "18e7ee9d-b4de-4060-aeb1-4331caed6db1"
      },
      "outputs": [],
      "source": [
        "#seleccionamos las columnas a utilizar. Todas menos la de la fecha y la del id\n",
        "df = dfBikes.iloc[:,2:]\n",
        "print(df)\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wZLo9s0kcc1",
        "outputId": "9ec55274-ddee-43dd-f599-c4775bcd4114"
      },
      "outputs": [],
      "source": [
        "#buscamos el mayor y menor valor de la clase\n",
        "MinRealY=df[\"Cuenta\"].min ()\n",
        "MaxRealY=df[\"Cuenta\"].max ()\n",
        "print(MinRealY)\n",
        "print(MaxRealY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um00oGSUkcc2",
        "outputId": "31df522d-6188-4db2-92cd-723265510f55"
      },
      "outputs": [],
      "source": [
        "#escalamos el dataframe\n",
        "scaler  = MinMaxScaler ()\n",
        "dataset = scaler.fit_transform(df)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC3MjhGdkcc2"
      },
      "outputs": [],
      "source": [
        "#separamos en conjunto de entrenamiento y de test\n",
        "train_size = int(len(df) * 0.67)\n",
        "test_size  = len(df) - train_size\n",
        "train = dataset[0:train_size,:]\n",
        "test  = dataset[train_size:len(df),:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGTiWL5Kkcc2"
      },
      "source": [
        "<h1>MLP</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Ko1yjAkcc3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eKR6e9Kkcc3"
      },
      "outputs": [],
      "source": [
        "#preparamos los datos\n",
        "trainX=train[:,0:12]\n",
        "trainY=train[:,13]\n",
        "testX=test[:,0:12]\n",
        "testY=test[:,13]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjNbSOFnkcc3",
        "outputId": "56b2c37d-7888-4cd2-9a7b-6c4af1abe810"
      },
      "outputs": [],
      "source": [
        "from contextlib import nullcontext\n",
        "\n",
        "#dataframe para almacenar las combinaciones de parametros y su RMSE medio obtenido en las 3 iteraciones\n",
        "dfError = pd.DataFrame(columns=[\"opt\",\"capas\",\"perdida\",\"batch\",\"epoca\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "optimizadores=[\"SGD\",\"adam\",\"RMSprop\"]\n",
        "funciones_perdidas=[\"mean_squared_error\",\"mean_absolute_error\",\"huber_loss\"]\n",
        "batch_sizes=[16,32,64]\n",
        "epocas=[6,10,14]\n",
        "capas=[1,3,5]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#recorremos parametros\n",
        "for capas_ind in range(len(capas)):\n",
        "  for perdida_ind in range(len(funciones_perdidas)):\n",
        "    for batch_ind in range(len(batch_sizes)):\n",
        "      for epoca_ind in range(len(epocas)):\n",
        "        for opt_ind in range(len(optimizadores)):\n",
        "\n",
        "          #imprimir por donde llegamos\n",
        "          print(\"\\n\\n\\n\")\n",
        "          print(\"capas:\",str(capas_ind))\n",
        "          print(\"perdida:\",str(perdida_ind))\n",
        "          print(\"batch:\",str(batch_ind))\n",
        "          print(\"epoca:\",str(epoca_ind))\n",
        "          print(\"opt:\",str(opt_ind))\n",
        "\n",
        "          #establecemos el optimizador\n",
        "          optimizer=None\n",
        "          if(optimizadores[opt_ind]==\"SGD\"):\n",
        "            optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "            print(\"SGD\")\n",
        "          if(optimizadores[opt_ind]==\"adam\"):\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "            print(\"Adam\")\n",
        "          if(optimizadores[opt_ind]==\"RMSprop\"):\n",
        "            optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "            print(\"RMSprop\")\n",
        "\n",
        "          #establecemos el modelo\n",
        "          modelNN_Keras = models.Sequential()\n",
        "          #aqui input_dim es 12 porque 12 atributos de entrada y salida la dejamos como sigmoid\n",
        "          #esta capa de entrada se mantiene siempre\n",
        "          modelNN_Keras.add(layers.Dense(units = 16, activation = 'relu', input_dim = 12))\n",
        "\n",
        "          #despues añadimos las capas intermedias que correspondan segun el valor del parametro\n",
        "          for _ in range(capas[capas_ind]):\n",
        "            modelNN_Keras.add(layers.Dense(units = 6, activation = 'relu'))\n",
        "\n",
        "          #la capa de salida se mantiene siempre\n",
        "          modelNN_Keras.add(layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "          modelNN_Keras.summary()\n",
        "\n",
        "          #para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteracion\n",
        "          i=0\n",
        "          acumulador=0\n",
        "\n",
        "          #repetimos 3 veces para cada modelo con su combinacion de parametros el proceso de entrenamiento y prediccion\n",
        "          for i in range(3):\n",
        "              #ajustamos el optimizador y la funcion de perdida\n",
        "              modelNN_Keras.compile(optimizer=optimizer, loss=funciones_perdidas[perdida_ind], metrics=['accuracy'])\n",
        "              #ajustamos las epocas y el batch_size\n",
        "              history = modelNN_Keras.fit(trainX, trainY, validation_split = 0.1, epochs=epocas[epoca_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n",
        "              #hacemos prediccion\n",
        "              y_pred = modelNN_Keras.predict(testX)\n",
        "              #evaluamos RMSE y lo vamos acumulando\n",
        "              rmse = math.sqrt(mean_squared_error(testY, y_pred))\n",
        "              acumulador=acumulador+rmse\n",
        "              print(\"ejecuccion: \",str(i))\n",
        "\n",
        "          #calculamos la media de RMSE en las 3 iteraciones\n",
        "          media=acumulador/3\n",
        "          print(\"media: \",str(media))\n",
        "          #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "          dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(capas[capas_ind]),str(funciones_perdidas[perdida_ind]),str(batch_sizes[batch_ind]),str(epocas[epoca_ind]), media]\n",
        "          print(\"completado parametros\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(dfError)\n",
        "dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/MLP_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SFhQ8cZkcc3"
      },
      "source": [
        "<h1>Preparacion de los datos para LSTM</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NkEdbBnkcc3"
      },
      "source": [
        "<h3>Train</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txYWTGg2kcc3",
        "outputId": "122aa755-ea4b-45f7-d4e6-264ef9f2d33b"
      },
      "outputs": [],
      "source": [
        "print(train)\n",
        "print(train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyWBJsqCkcc4"
      },
      "outputs": [],
      "source": [
        "#Convertimos los datos en un formato adecuado para LSTM\n",
        "trainX, trainY = CreaDatos(train, Historia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvdhlGvCkcc4",
        "outputId": "00a28efd-abcb-4782-fb4e-ce5412c149c8"
      },
      "outputs": [],
      "source": [
        "print(trainX)\n",
        "print(trainX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOr4vhNRkcc4",
        "outputId": "735ddc19-e062-4b63-db09-f96aa39ce198"
      },
      "outputs": [],
      "source": [
        "print(trainY)\n",
        "print(trainY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ7svZPOkcc4"
      },
      "source": [
        "<h3>Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZq0iTcvkcc4",
        "outputId": "a209382b-ae48-402e-eea5-ec917d6c701d"
      },
      "outputs": [],
      "source": [
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60QSyjWwkcc4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Convertimos los datos en un formato adecuado para LSTM\n",
        "testX, testY   = CreaDatos(test, Historia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcJpeWUGkcc4",
        "outputId": "edf224f9-c0c7-4020-e072-7f9cb32d463e"
      },
      "outputs": [],
      "source": [
        "print(testX)\n",
        "print(testX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgIPAkxskcc5",
        "outputId": "dee3a3e3-9f56-4759-98ad-5cce8e5f065e"
      },
      "outputs": [],
      "source": [
        "print(testY)\n",
        "print (testY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axik_-S6kcc5"
      },
      "source": [
        "<h1>LSTM para un problema de regresion</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8GUJMzjdkcc5",
        "outputId": "07dfc6fd-8033-4d73-fb8a-f0280f87a3c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#dataframe para almacenar el RMSE con las diferentes combinaciones de parametros\n",
        "dfError = pd.DataFrame(columns=[\"func_salida\",\"LSTM_dim\",\"batch\",\"epoca\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "func_salida=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n",
        "batch_sizes=[16,32,64]\n",
        "epocas=[6,10,14]\n",
        "LSTM_dim=[4,8,12,16]\n",
        "\n",
        "func_salida_ind=0\n",
        "batch_ind=0\n",
        "epocas_ind=0\n",
        "LSTM_dim_ind=0\n",
        "\n",
        "#recorremos parametros\n",
        "for func_salida_ind in range(len(func_salida)):\n",
        "  for batch_ind in range(len(batch_sizes)):\n",
        "    for epocas_ind in range(len(epocas)):\n",
        "      for LSTM_dim_ind in range(len(LSTM_dim)):\n",
        "\n",
        "        #imprimir por donde llegamos\n",
        "        print(\"\\n\\n\\n\")\n",
        "        print(\"func_salida:\",str(func_salida_ind))\n",
        "        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n",
        "        print(\"batch:\",str(batch_ind))\n",
        "        print(\"epoca:\",str(epocas_ind))\n",
        "        #ajustamos los parametros para cuando vaya a hacer la prediccion en la funcion CalculoRMSE\n",
        "        BATCHSIZE=batch_sizes[batch_ind]\n",
        "        EPOCAS=epocas[epocas_ind]\n",
        "        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n",
        "\n",
        "        #creamos el modelo\n",
        "        model = Sequential()\n",
        "        #ajustamos parametro lstm_dim\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape[1],trainX.shape[2])))\n",
        "        #ajustamos parametro funcion de salida\n",
        "        model.add(Dense(1, activation=func_salida[func_salida_ind]))\n",
        "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "        model.summary()\n",
        "\n",
        "        #para realizar las 3 iteraciones y acumular el RMSE de cada iteracion\n",
        "        i=0\n",
        "        acumulador=0\n",
        "\n",
        "        #realizamos 3 veces con el modelo el entrenamiento\n",
        "        for i in range(3):\n",
        "\n",
        "            #ajustamos el batch_size y el numero de epocas\n",
        "            model.fit(trainX, trainY[:,13], epochs=epocas[epocas_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n",
        "\n",
        "            #llamamos a la funcion que obtiene el RMSE y realiza la grafica para comparar los valores reales con los predichos\n",
        "            testScore=CalculoRMSE (\"LSTM-vainilla\")\n",
        "            acumulador=acumulador+testScore\n",
        "            print(\"ejecuccion: \",str(i))\n",
        "\n",
        "        #calculamos la media de RMSE en las 3 iteraciones\n",
        "        media=acumulador/3\n",
        "        print(\"media: \",str(media))\n",
        "        #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "        dfError.loc[len(dfError)] = [str(func_salida[func_salida_ind]),str(LSTM_dim[LSTM_dim_ind]),str(batch_sizes[batch_ind]),str(epocas[epocas_ind]), media]\n",
        "        print(\"completado parametros\\n\\n\")\n",
        "\n",
        "#guardamos el dataframe\n",
        "print(dfError)\n",
        "dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/LSTM_1_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUXHTjZ6kcc5"
      },
      "source": [
        "<h1>LSTM utilizando una ventana temporal</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZt6XaCekcc5",
        "outputId": "cb44151a-7cf8-46fb-824e-c451dea9ebfa"
      },
      "outputs": [],
      "source": [
        "#Convertimos los datos en un formato adecuado para LSTM\n",
        "Historia = 3\n",
        "trainX, trainY = CreaDatos (train, Historia)\n",
        "testX, testY   = CreaDatos (test, Historia)\n",
        "\n",
        "print (trainX.shape, trainY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zjR2tthUkcc5",
        "outputId": "99865111-7a2e-4e27-c19d-603959b7a107"
      },
      "outputs": [],
      "source": [
        "\n",
        "#dataframe para almacenar las combinaciones de parametros y su RMSE medio obtenido en las 3 iteraciones\n",
        "dfError = pd.DataFrame(columns=[\"opt\",\"LSTM_dim\",\"perdida\",\"epoca\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "optimizadores=[\"SGD\",\"adam\",\"RMSprop\"]\n",
        "funciones_perdidas=[\"mean_squared_error\",\"mean_absolute_error\",\"huber_loss\"]\n",
        "epocas=[6,10,14]\n",
        "LSTM_dim=[2,5,10]\n",
        "\n",
        "\n",
        "\n",
        "LSTM_dim_ind=0\n",
        "perdida_ind=0\n",
        "epoca_ind=0\n",
        "opt_ind=0\n",
        "\n",
        "#recorremos parametros\n",
        "for LSTM_dim_ind in range(len(LSTM_dim)):\n",
        "  for perdida_ind in range(len(funciones_perdidas)):\n",
        "    for epoca_ind in range(len(epocas)):\n",
        "        for opt_ind in range(len(optimizadores)):\n",
        "\n",
        "          #imprimir por donde llegamos\n",
        "          print(\"\\n\\n\\n\")\n",
        "          print(\"LSTM_dim:\",str(LSTM_dim_ind))\n",
        "          print(\"perdida:\",str(perdida_ind))\n",
        "          print(\"epoca:\",str(epoca_ind))\n",
        "          print(\"opt:\",str(opt_ind))\n",
        "          #ajustamos los parametros para cuando vaya a hacer la prediccion en la funcion CalculoRMSE\n",
        "          BATCHSIZE=1\n",
        "          EPOCAS=epocas[epoca_ind]\n",
        "          LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n",
        "\n",
        "          #establecemos el optimizador\n",
        "          optimizer=None\n",
        "          if(optimizadores[opt_ind]==\"SGD\"):\n",
        "            optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "            print(\"SGD\")\n",
        "          if(optimizadores[opt_ind]==\"adam\"):\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "            print(\"Adam\")\n",
        "          if(optimizadores[opt_ind]==\"RMSprop\"):\n",
        "            optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "            print(\"RMSprop\")\n",
        "\n",
        "          #creamos el modelo\n",
        "          model = Sequential()\n",
        "          #ajustamos parametro LSTM_dim\n",
        "          model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape [1], trainX.shape[2])))\n",
        "          model.add(Dense(1, activation='sigmoid'))\n",
        "          #ajustamos optimizador y funcion de perdida\n",
        "          model.compile(loss=funciones_perdidas[perdida_ind], optimizer=optimizer)\n",
        "\n",
        "          #para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteracion\n",
        "          i=0\n",
        "          acumulador=0\n",
        "\n",
        "          for i in range(3):\n",
        "              #entrenamos el modelo y ajustamos epocas\n",
        "              model.fit(trainX, trainY[:,13], epochs=epocas[epoca_ind], batch_size=1, verbose=0)\n",
        "\n",
        "              #llamamos a la funcion que obtiene el RMSE y realiza la grafica para comparar los valores reales con los predichos\n",
        "              testScore=CalculoRMSE (\"LSTM-vainilla\")\n",
        "              acumulador=acumulador+testScore\n",
        "              print(\"ejecuccion: \",str(i))\n",
        "\n",
        "          #calculamos la media de RMSE en las 3 iteraciones\n",
        "          media=acumulador/3\n",
        "          print(\"media: \",str(media))\n",
        "          #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "          dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(LSTM_dim[LSTM_dim_ind]),str(funciones_perdidas[perdida_ind]),str(epocas[epoca_ind]), media]\n",
        "          print([str(optimizadores[opt_ind]),str(LSTM_dim[LSTM_dim_ind]),str(funciones_perdidas[perdida_ind]),str(epocas[epoca_ind]), media])\n",
        "          print(\"completado parametros\\n\\n\")\n",
        "\n",
        "          #guardamos el dataframe\n",
        "          print(dfError)\n",
        "          dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/LSTM_2_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwdWZB_8kcc5"
      },
      "source": [
        "<h1>LSTM apiladas</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNFGtqGfkcc5",
        "outputId": "5cc511b0-5137-42da-c4ce-33439eca1d5f"
      },
      "outputs": [],
      "source": [
        "#Convertimos los datos en un formato adecuado para LSTM\n",
        "historia = 1\n",
        "trainX, trainY = CreaDatos (train, historia)\n",
        "testX, testY   = CreaDatos (test, historia)\n",
        "\n",
        "print (trainX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bc1zj2B9kcc6",
        "outputId": "e7c9df33-9d16-4265-9102-615068d5d5bd"
      },
      "outputs": [],
      "source": [
        "#dataframe para almacenar el RMSE con las diferentes combinaciones de parametros\n",
        "dfError = pd.DataFrame(columns=[\"opt\",\"batch\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "optimizadores=[\"RMSprop\",\"adam\",\"SGD\"]\n",
        "batch_sizes=[16,32,64]\n",
        "epocas=[6,10,14]\n",
        "LSTM_dim=[4,8,12]\n",
        "\n",
        "\n",
        "func_perdida_ind=0\n",
        "batch_ind=0\n",
        "epocas_ind=0\n",
        "LSTM_dim_ind=0\n",
        "opt_ind=0\n",
        "\n",
        "#recorremos parametros\n",
        "\n",
        "for batch_ind in range(len(batch_sizes)):\n",
        "  for epocas_ind in range(len(epocas)):\n",
        "    for LSTM_dim_ind in range(len(LSTM_dim)):\n",
        "      for opt_ind in range(len(optimizadores)):\n",
        "\n",
        "        #imprimir por donde llegamos\n",
        "        print(\"\\n\\n\\n\")\n",
        "        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n",
        "        print(\"batch:\",str(batch_ind))\n",
        "        print(\"epoca:\",str(epocas_ind))\n",
        "        print(\"optimizador:\",str(opt_ind))\n",
        "        #ajustamos los parametros para cuando vaya a hacer la prediccion en la funcion CalculoRMSE\n",
        "        BATCHSIZE=batch_sizes[batch_ind]\n",
        "        EPOCAS=epocas[epocas_ind]\n",
        "        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n",
        "\n",
        "\n",
        "        #establecemos el optimizador\n",
        "        optimizer=None\n",
        "        if(optimizadores[opt_ind]==\"SGD\"):\n",
        "          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "          print(\"SGD\")\n",
        "        if(optimizadores[opt_ind]==\"adam\"):\n",
        "          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "          print(\"Adam\")\n",
        "        if(optimizadores[opt_ind]==\"RMSprop\"):\n",
        "          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "          print(\"RMSprop\")\n",
        "\n",
        "\n",
        "\n",
        "        #creamos el modelo y entrenamos\n",
        "        model = Sequential()\n",
        "        #ajustamos parametro LSTM_Dim\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind], input_shape=(trainX.shape[1],trainX.shape[2]), return_sequences=True))\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind]))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        #ajustamos optimizador y funcion de perdida\n",
        "        model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
        "\n",
        "\n",
        "        #para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteracion\n",
        "        i=0\n",
        "        acumulador=0\n",
        "\n",
        "        #entrenamos modelo 3 veces\n",
        "        for i in range(3):\n",
        "            #ajustamos epocas y batch size\n",
        "            model.fit(trainX, trainY[:,13], epochs=epocas[epocas_ind], batch_size=batch_sizes[batch_ind], verbose=0)\n",
        "            #llamamos a la funcion que obtiene el RMSE y realiza la grafica para comparar los valores reales con los predichos\n",
        "            testScore=CalculoRMSE (\"LSTM-dos capas\")\n",
        "            acumulador=acumulador+testScore\n",
        "            print(\"ejecuccion: \",str(i))\n",
        "\n",
        "        #calculamos la media de RMSE en las 3 iteraciones\n",
        "        media=acumulador/3\n",
        "        print(\"media: \",str(media))\n",
        "        #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "        dfError.loc[len(dfError)] = [str(optimizadores[opt_ind]),str(batch_sizes[batch_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n",
        "        print(\"completado parametros\\n\\n\")\n",
        "\n",
        "        #guardamos el dataframe\n",
        "        print(dfError)\n",
        "        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/LSTM_3_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFisDC3kcc6"
      },
      "source": [
        "<h1>LSTM con memoria entre lote y lote</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqchrJgAkcc6",
        "outputId": "31a22cde-b736-420f-a187-ae54c22c0635"
      },
      "outputs": [],
      "source": [
        "#dataframe para almacenar el RMSE con las diferentes combinaciones de parametros\n",
        "dfError = pd.DataFrame(columns=[\"func_act\",\"opt\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "func_activacion=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n",
        "optimizadores=[\"RMSprop\",\"SGD\",\"adam\"]\n",
        "epocas=[6,10,14]\n",
        "LSTM_dim=[4,8,12]\n",
        "\n",
        "\n",
        "\n",
        "#recorremos parametros\n",
        "for func_activacion_ind in range(len(func_activacion)):\n",
        "  for opt_ind in range(len(optimizadores)):\n",
        "    for epocas_ind in range(len(epocas)):\n",
        "      for LSTM_dim_ind in range(len(LSTM_dim)):\n",
        "\n",
        "        #imprimir por donde llegamos\n",
        "        print(\"\\n\\n\\n\")\n",
        "        print(\"func_acticacion:\",str(func_activacion_ind))\n",
        "        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n",
        "        print(\"optimizador:\",str(opt_ind))\n",
        "        print(\"epoca:\",str(epocas_ind))\n",
        "        #ajustamos los parametros para cuando vaya a hacer la prediccion en la funcion CalculoRMSE\n",
        "        BATCHSIZE=1\n",
        "        EPOCAS=epocas[epocas_ind]\n",
        "        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n",
        "\n",
        "        #establecemos el optimizador\n",
        "        optimizer=None\n",
        "        if(optimizadores[opt_ind]==\"SGD\"):\n",
        "          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "          print(\"SGD\")\n",
        "        if(optimizadores[opt_ind]==\"adam\"):\n",
        "          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "          print(\"Adam\")\n",
        "        if(optimizadores[opt_ind]==\"RMSprop\"):\n",
        "          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "          print(\"RMSprop\")\n",
        "\n",
        "\n",
        "\n",
        "        #creamos el modelo y entrenamos\n",
        "        batch_size_alterado = 1\n",
        "        model = Sequential()\n",
        "        #ajustamos parametro LSTM_dim\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape [1], trainX.shape [2]), stateful=True))\n",
        "        #despues añadimos las capas intermedias que correspondan segun el valor del parametro\n",
        "\n",
        "        #capa de salida se mantiene\n",
        "        model.add(Dense(1, activation=func_activacion[func_activacion_ind]))\n",
        "        #ajusto optimizador\n",
        "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "        #para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteracion\n",
        "        i=0\n",
        "        acumulador=0\n",
        "        k=0\n",
        "\n",
        "        #repetimos 3 veces el entrenamiento\n",
        "        for i in range(3):\n",
        "            #en este modelo, realizamos tantas iteraciones como epocas\n",
        "            for k in range(epocas[epocas_ind]):\n",
        "                #ajustamos el parametro de batch\n",
        "                model.fit(trainX, trainY[:,13], epochs=1, batch_size=1, verbose=0, shuffle=False)\n",
        "\n",
        "                #llamamos a la funcion que obtiene el RMSE y realiza la grafica para comparar los valores reales con los predichos\n",
        "                testScore=CalculoRMSE(\"LSTM - con memoria entre lote y lote\")\n",
        "                acumulador=acumulador+testScore\n",
        "                print(\"ejecuccion: \",str(i))\n",
        "\n",
        "                model.reset_states()\n",
        "\n",
        "\n",
        "        #calculamos la media de RMSE en las 3 iteraciones\n",
        "        media=acumulador/3\n",
        "        print(\"media: \",str(media))\n",
        "        #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "        dfError.loc[len(dfError)] = [str(func_activacion[func_activacion_ind]),str(optimizadores[opt_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n",
        "        print(\"completado parametros\\n\\n\")\n",
        "\n",
        "        #guardamos el dataframe\n",
        "        print(dfError)\n",
        "        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/LSTM_4_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vOLd9K6kcc6"
      },
      "source": [
        "<h1>LSTM's apilados (varias capas) con memoria entre lote y lote</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w2k0vKMMkcc6",
        "outputId": "c8decc04-80de-4eea-c674-1894e8db954a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "#dataframe para almacenar el RMSE con las diferentes combinaciones de parametros\n",
        "dfError = pd.DataFrame(columns=[\"func_activacion\",\"opt\",\"epoca\",\"LSTM_dim\", \"RMSE\"])\n",
        "\n",
        "#parametros a evaluar y sus valores diferentes\n",
        "func_activacion=[\"sigmoid\",\"relu\",\"tanh\",\"linear\"]\n",
        "optimizadores=[\"RMSprop\",\"SGD\",\"adam\"]\n",
        "epocas=[6,10,14]\n",
        "LSTM_dim=[4,8,12,16]\n",
        "\n",
        "\n",
        "\n",
        "#recorremos parametros\n",
        "for func_activacion_ind in range(len(func_activacion)):\n",
        "  for opt_ind in range(len(optimizadores)):\n",
        "    for epocas_ind in range(len(epocas)):\n",
        "      for LSTM_dim_ind in range(len(LSTM_dim)):\n",
        "\n",
        "        #imprimir por donde llegamos\n",
        "        print(\"\\n\\n\\n\")\n",
        "        print(\"func_activacion:\",str(func_activacion_ind))\n",
        "        print(\"LSTM_dim:\",str(LSTM_dim_ind))\n",
        "        print(\"optimizador:\",str(opt_ind))\n",
        "        print(\"epoca:\",str(epocas_ind))\n",
        "        #ajustamos los parametros para cuando vaya a hacer la prediccion en la funcion CalculoRMSE\n",
        "        BATCHSIZE=1\n",
        "        EPOCAS=epocas[epocas_ind]\n",
        "        LSTM_DIM=LSTM_dim[LSTM_dim_ind]\n",
        "\n",
        "        #establecemos el optimizador\n",
        "        optimizer=None\n",
        "        if(optimizadores[opt_ind]==\"SGD\"):\n",
        "          optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "          print(\"SGD\")\n",
        "        if(optimizadores[opt_ind]==\"adam\"):\n",
        "          optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "          print(\"Adam\")\n",
        "        if(optimizadores[opt_ind]==\"RMSprop\"):\n",
        "          optimizer = keras.optimizers.RMSprop(learning_rate=1e-3)\n",
        "          print(\"RMSprop\")\n",
        "\n",
        "        #creamos el modelo y entrenamos\n",
        "        batch_size_alterado = 1\n",
        "        model = Sequential()\n",
        "        #ajustamos parametro LSTM_dim\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape[1], trainX.shape[2]), stateful=True, return_sequences=True))\n",
        "        model.add(LSTM(LSTM_dim[LSTM_dim_ind], batch_input_shape=(batch_size_alterado, trainX.shape[1], trainX.shape[2]), stateful=True))\n",
        "        #ajustamos parametro func activacion salida\n",
        "        model.add(Dense(1, activation=func_activacion[func_activacion_ind]))\n",
        "        model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "        #para repetir 3 veces el entreno sobre cada modelo y acumular el RMSE de cada iteracion\n",
        "        i=0\n",
        "        acumulador=0\n",
        "        k=0\n",
        "\n",
        "        #repetimos 3 veces el entreno\n",
        "        for i in range(3):\n",
        "            #recorremos bucle tantas epocas tengamos\n",
        "            for k in range(epocas[epocas_ind]):\n",
        "                #ajustamos parametro batch_size\n",
        "                model.fit(trainX, trainY[:,13], epochs=1, batch_size=BATCHSIZE, verbose=0, shuffle=False)\n",
        "                #llamamos a la funcion que obtiene el RMSE y realiza la grafica para comparar los valores reales con los predichos\n",
        "                testScore=CalculoRMSE(\"prueba\")\n",
        "                acumulador=acumulador+testScore\n",
        "                print(\"ejecuccion: \",str(i))\n",
        "\n",
        "                model.reset_states()\n",
        "\n",
        "\n",
        "        #calculamos la media de RMSE en las 3 iteraciones\n",
        "        media=acumulador/3\n",
        "        print(\"media: \",str(media))\n",
        "        #Lo almacenamos en el dataframe junto a los parametros seleccionados\n",
        "        dfError.loc[len(dfError)] = [str(func_activacion[func_activacion_ind]),str(optimizadores[opt_ind]),str(epocas[epocas_ind]),str(LSTM_dim[LSTM_dim_ind]), media]\n",
        "        print(\"completado parametros\\n\\n\")\n",
        "\n",
        "        #guardamos el dataframe\n",
        "        print(dfError)\n",
        "        dfError.to_csv(\"/content/drive/MyDrive/Colab Notebooks/LSTM_5_resultados.csv\", index=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "8e5e9526956f0969fe605d41ae39091028f4f1b8fb42028371b20ef3bd5381d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
